{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ui64MvfB2nzJ"
      },
      "outputs": [],
      "source": [
        "#Read https://github.com/frcs/EE4C16-self-driving-lab for more info.\n",
        "\n",
        "\n",
        "# In this lab you will train a neural net to drive a virtual driving simulator,\n",
        "# using data recorded from your own manual operation of the sim.\n",
        "#\n",
        "# Your model will attempt to predict the correct steering angle, given the input\n",
        "# images, using your recorded laps as training data.\n",
        "#\n",
        "# Your model will be operating in cruise control mode; it does not have any throttle\n",
        "# input, and will not be able to reverse.\n",
        "#\n",
        "# Collecting Training Data\n",
        "# ========================\n",
        "# Step 1 is to run the simulator on your local machine (eg. within Windows, in the CADLab\n",
        "#        or on your own computer) and drive around while recording training data (press 'R').  \n",
        "#        For each timestep in your driving, three images are recorded: the center \n",
        "#        (straight ahead) view, and also left and right views.  \n",
        "#        Your steering angle is also recorded.\n",
        "#\n",
        "# Step 2: You will zip the IMG directory and the driving_log.csv file into a zip file that you will \n",
        "#         name recordings.zip and upload this zip file inside your Drive at /data/recordings.zip \n",
        "#\n",
        "# Step 3: In this notebook's VM, you will unzip recordings.zip to have a local copy\n",
        "#\n",
        "# Designing/Training the DNN\n",
        "# ==========================\n",
        "# Step 4: In the notebook, Design and train a DNN to predict the steering angle from an image\n",
        "#\n",
        "# Evaluation\n",
        "# ==========\n",
        "# Step 5: Download the model to your workstation and use it to pilot the car around the track ('autonomous mode')\n",
        "#\n",
        "# Step 6: You will upload the record of the car's positions back to your lab directory in Google Drive..\n",
        "#\n",
        "# Step 7: push for assessment\n",
        "#\n",
        "# You can repeat steps 3-7 when tweaking your network.\n",
        "# You can also repeat step 1-3 if you decide you need more or more varied training data."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary modules\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from tensorflow.keras import datasets\n",
        "from tensorflow.keras.layers import Input, Dense, Flatten, Dropout, Activation \n",
        "from tensorflow.keras.layers import PReLU, LeakyReLU, Conv2D, Lambda, MaxPooling2D\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "\n",
        "from tensorflow.keras.models import model_from_json\n",
        "\n",
        "from IPython.display import clear_output\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from matplotlib.ticker import MaxNLocator\n",
        "\n",
        "import random\n",
        "import ntpath\n",
        "import csv\n",
        "import PIL\n"
      ],
      "metadata": {
        "id": "TZV5_bwK3l0a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define some useful functions\n",
        "class PlotLoss(keras.callbacks.Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.i = 0\n",
        "        self.x = []\n",
        "        self.losses = []\n",
        "        self.val_losses = []\n",
        "        self.logs = []\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        self.logs.append(logs)\n",
        "        self.x.append(int(self.i))\n",
        "        self.losses.append(logs.get('loss'))\n",
        "        self.val_losses.append(logs.get('val_loss'))\n",
        "        self.i += 1\n",
        "        \n",
        "        clear_output(wait=True)\n",
        "        plt.figure(figsize=(16, 6))\n",
        "        plt.plot([1, 2])\n",
        "        plt.subplot(121) \n",
        "        plt.plot(self.x, self.losses, label=\"train loss\")\n",
        "        plt.plot(self.x, self.val_losses, label=\"validation loss\")\n",
        "        plt.gca().xaxis.set_major_locator(MaxNLocator(integer=True))\n",
        "        plt.ylabel('loss')\n",
        "        plt.xlabel('epoch')\n",
        "        plt.title('Model Loss (MSE)')\n",
        "        plt.legend()\n",
        "        plt.show();\n",
        "        "
      ],
      "metadata": {
        "id": "XSDCnaDC3nil"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def import_csv_data(logfile):\n",
        "    with open(logfile, 'r') as f:\n",
        "        data = list(csv.reader(f, skipinitialspace=True, delimiter=',', quoting=csv.QUOTE_NONE))\n",
        "\n",
        "    # Each row of the CSV contains the data from one timestep of the training recording.\n",
        "    # Column semantics are as follows:\n",
        "    center = 0   # Path (or filename) of image file containing center view\n",
        "    left = 1     # Image file containing left view\n",
        "    right = 2    # Image file containing right view\n",
        "    angle = 3    # Desired orientation of car (steering angle)\n",
        "    accel = 4    # Acceleration (throttle)\n",
        "    stop = 5     # Not sure what this..\n",
        "    speed = 6    # Speed\n",
        "\n",
        "    # Condense the recorded data into a map of image files (input) to steering angle (output).\n",
        "    # Note that in the simulation, when our NN-model is driving, it will be provided the \n",
        "    # only front image as input.\n",
        "    parsed_data = dict()\n",
        "\n",
        "    for row in data:  # 'row' is an array with values corresponding to columns in the CSV.\n",
        "        # Skip examples with a quasi-static car.\n",
        "        if float(row[speed]) < 0.01:\n",
        "            continue  \n",
        "        \n",
        "        center_image = '/content/recordings/IMG/' + ntpath.basename(row[center])\n",
        "        left_image = '/content/recordings/IMG/' + ntpath.basename(row[left])\n",
        "        right_image = '/content/recordings/IMG/' + ntpath.basename(row[right])\n",
        "        \n",
        "        parsed_data[center_image] = float(row[angle])\n",
        "        \n",
        "        # This is a trick to maximize the data available.  Have a think about what is going on here...\n",
        "        parsed_data[left_image] = float(row[angle]) + 0.20\n",
        "        parsed_data[right_image] = float(row[angle]) - 0.20\n",
        "\n",
        "    return parsed_data"
      ],
      "metadata": {
        "id": "UOLmnWg73u91"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_image(path_to_jpg):\n",
        "    im = PIL.Image.open(path_to_jpg)\n",
        "    im_width = im.size[0]\n",
        "    im_height = im.size[1]\n",
        "    \n",
        "    # We are going to discard the sky and the car, to focus training on the road.\n",
        "    # This crop isolates that portion.  You can see the effects by changing the values\n",
        "    # and re-evaluating that cell, but they must match the original values (top=50, bottom=140)\n",
        "    # when you train so as to match the input supplied from the simulator.\n",
        "    left = 0\n",
        "    right = im_width\n",
        "    top = 50 # 0\n",
        "    bottom = 140 # im_height\n",
        "    \n",
        "    im = im.crop((left, top, right, bottom))\n",
        "    \n",
        "    # We can shrink the image a bit to reduce training time.\n",
        "    im = im.resize((200, 66), PIL.Image.BICUBIC)\n",
        "    im = np.asarray(im)\n",
        "    return im\n",
        "\n",
        "A = next(iter(training_data.items()))\n",
        "print(A)\n",
        "im = load_image(A[0])\n",
        "plt.imshow(im)\n"
      ],
      "metadata": {
        "id": "u7yRGExx3vYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_generator(training_data, batch_size, reject_above=True, reject_thresh=0.0):\n",
        "    inputs_batch = []\n",
        "    targets_batch = []\n",
        "    \n",
        "    while True:\n",
        "        random.seed(42)\n",
        "        for idx, (k, v) in enumerate(training_data.items()):\n",
        "            sample = random.random()\n",
        "            reject_item = ((sample > reject_thresh and reject_above) or\n",
        "                        (sample <= reject_thresh and not reject_above))\n",
        "            \n",
        "            if not reject_item:\n",
        "                decoded_image = load_image(k)\n",
        "                # Important--as we've stressed before--to scale the input data to -1..1.\n",
        "                decoded_image = 2.0*decoded_image/255 - 1\n",
        "                label = v\n",
        "\n",
        "                inputs_batch.append(decoded_image)\n",
        "                targets_batch.append(label)\n",
        "\n",
        "            if (len(inputs_batch)+1) % batch_size == 0:\n",
        "                yield (np.asarray(inputs_batch), np.asarray(targets_batch))\n",
        "                inputs_batch.clear()\n",
        "                targets_batch.clear()\n"
      ],
      "metadata": {
        "id": "dt9PjHaJ4KBj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define your model in this cell.\n",
        "# See the paper 'End to End Learning for Self-Driving Cars' (Bojarski et al) for some ideas.\n",
        "\n",
        "inputs = Input(shape=(66, 200, 3))\n",
        "x = inputs\n",
        "x = MaxPooling2D(pool_size=(2,2), padding = 'same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2D(24, kernel_size = (5,5), strides = (2,2), activation='relu', padding = 'valid')(x)\n",
        "x = Dropout(0.1)(x)\n",
        "x = Conv2D(36, kernel_size = (5,5), strides = (2,2), activation='relu', padding = 'valid')(x)\n",
        "x = Dropout(0.1)(x)\n",
        "x = Conv2D(48, kernel_size = (5,5), strides = (2,2), activation='relu', padding = 'valid')(x)\n",
        "x = Dropout(0.1)(x)\n",
        "x = Conv2D(64, kernel_size = (3,3), activation='relu', padding = 'same')(x)\n",
        "x = Dropout(0.1)(x)\n",
        "x = Conv2D(64, kernel_size = (3,3), activation='relu', padding = 'same')(x)\n",
        "x = Dropout(0.1)(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(100, activation= 'relu')(x)\n",
        "x = Dropout(0.1)(x)\n",
        "x = Dense(50, activation= 'relu')(x)\n",
        "x = Dropout(0.1)(x)\n",
        "x = Dense(10, activation= None)(x)\n",
        "x = Dropout(0.1)(x)\n",
        "\n",
        "## Add your layers here...  \n",
        "## (DO NOT ADD A LAMBDA LAYER to scale the input -- which you might see used in other online examples\n",
        "##   -- we do our scaling of input data in the data_generator, above).\n",
        "\n",
        "## Your output is a single float: the desired steering angle.\n",
        "output = Dense(1)(x)\n",
        "\n",
        "model = keras.models.Model(inputs=inputs, outputs=output)\n",
        "model.summary()\n",
        "model.compile(optimizer='adam', loss='mse')"
      ],
      "metadata": {
        "id": "PspIhWiW4JhG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training.  Re-evaluate this cell repeatedly to train more.\n",
        "batch_size = 64\n",
        "validation_fraction = 0.1  # Probably best to leave this value alone...\n",
        "model.fit_generator(\n",
        "    generator=data_generator(training_data, batch_size=64, reject_above=False, reject_thresh=validation_fraction),\n",
        "    validation_data=data_generator(training_data, batch_size=64, reject_above=True, reject_thresh=validation_fraction),\n",
        "    steps_per_epoch=int((1-validation_fraction)*len(training_data))//batch_size,\n",
        "    validation_steps=int(validation_fraction*len(training_data))//batch_size,\n",
        "    epochs=20,\n",
        "    verbose=1,\n",
        "    callbacks=[PlotLoss()],\n",
        "    shuffle=True\n",
        ")"
      ],
      "metadata": {
        "id": "87w5_Px_4Tz5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model to disk (when done training).\n",
        "model.save('model.h5')"
      ],
      "metadata": {
        "id": "FCPD4H3a4nKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now: \n",
        "# * download your model to your computer\n",
        "# * run the simulator in autonomous mode\n",
        "# * kick off your robot driver (python drive.py model.h5)\n",
        "# * wait for the car to crash, or head happily into the sunset, or whatever\n",
        "# * close or quit the simulator\n",
        "# * terminate your robot driver (ctrl-c in the console window)\n",
        "# * upload the file 'car_positions.npz' from your workstation to the dir on your drive\n",
        "# * git commit push for assessment"
      ],
      "metadata": {
        "id": "c-2Sffvd4nmO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}